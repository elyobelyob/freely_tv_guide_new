#!/usr/bin/env python3
import argparse
import json
import os
import re
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from xml.etree import ElementTree as ET

import requests

EPG_XML_URL = "https://raw.githubusercontent.com/dp247/Freeview-EPG/master/epg.xml"

# Local image placeholders (the workflow step creates these files)
PROG_PLACEHOLDER = "img/programmes/placeholder.svg"
CHAN_PLACEHOLDER = "img/channels/placeholder.svg"

_iso_dur_re = re.compile(r"PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?")

# --- Helpers ---------------------------------------------------------------

def _iso_to_minutes(s: str):
    m = _iso_dur_re.fullmatch(s or "")
    if not m:
        return None
    h = int(m.group(1) or 0)
    mi = int(m.group(2) or 0)
    se = int(m.group(3) or 0)
    return h * 60 + mi + (se // 60)

def slugify(text: str) -> str:
    text = text.lower().strip()
    text = re.sub(r"[^a-z0-9]+", "-", text)
    return text.strip("-") or "channel"


def ensure_dir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)


def read_config(config_path: Optional[Path]) -> Dict[str, Any]:
    if not config_path:
        return {}
    with open(config_path, "r", encoding="utf-8") as f:
        import yaml  # lightweight, only used when config provided
        return yaml.safe_load(f) or {}


# --- Compatibility layer (best‑effort mapping to older Freesat/Freeview shape)
# Target shape (per channel file):
#   {
#     "channel": {"id": "560", "name": "BBC One"},
#     "events": [
#        {"startTime": 1696165200, "duration": 60, "name": "Title",
#         "description": "...", "image": "/path/or/url.jpg"},
#        ...
#     ],
#     "compat": {
#        "freesat_card": [ {"event": [...] } ]
#     }
#   }
# The extra compat.freesat_card[0].event mirrors the old sensor’s expectations
# (value_json.0.event), while preserving a clean top‑level shape.

Event = Dict[str, Any]
Channel = Dict[str, Any]


def _pick(d: Dict[str, Any], keys: List[str], default=None):
    for k in keys:
        if k in d and d[k] is not None:
            return d[k]
    return default


def normalise_event(ev: Dict[str, Any]) -> Dict[str, Any]:
    start = _pick(ev, ["startTime", "start", "start_time", "start_timestamp", "time", "begin"])
    dur   = _pick(ev, ["duration", "durationMinutes", "duration_minutes", "dur", "length", "runtime"])

    main = _pick(ev, ["name", "title", "main_title", "programme", "program", "programmeTitle", "show"]) or ""
    # secondary title (what your card calls "description")
    secondary = _pick(ev, ["secondary_title", "subtitle", "episode_title"]) or ""
    # actual synopsis/blurbs (we'll keep this in a separate field)
    synopsis = _pick(ev, ["description", "synopsis", "shortSynopsis", "longSynopsis", "summary"]) or ""

    image = _pick(ev, ["image", "imageUrl", "image_url", "imageURL", "poster", "thumbnail", "fallback_image_url"]) or ""

    # duration normalisation
    if isinstance(dur, (int, float)) and dur > 600:
        dur = round(dur / 60)
    if isinstance(dur, str) and dur.startswith("PT"):
        m = _iso_to_minutes(dur)
        if m is not None:
            dur = m

    end = _pick(ev, ["endTime", "end", "end_time", "stop", "finish"])
    if dur is None and isinstance(start, (int, float)) and isinstance(end, (int, float)):
        dur = int(round((end - start) / 60))

    # keep _raw intact (need image_url/fallback_image_url for mirroring)
    raw = dict(ev)

    # leave event.image blank if remote; CI will fill local/placeholder
    if isinstance(image, str) and image.strip().lower().startswith(("http://", "https://")):
        image = ""

    # IMPORTANT: map secondary title into "description" for your frontend
    description_for_card = secondary or synopsis

    return {
        "startTime": start,
        "duration": dur,
        "name": main,                  # main title
        "description": description_for_card,  # what your card prints
        "synopsis": synopsis,          # full blurb preserved here
        "image": image,
        "_raw": raw,
    }


def extract_channels(payload):
    # Freely: { status, data: { programs: [ ... ] } }
    if isinstance(payload, dict):
        data = payload.get("data")
        if isinstance(data, dict):
            progs = data.get("programs")
            if isinstance(progs, list) and progs and isinstance(progs[0], dict):
                return progs
    # fallback to old heuristics if needed
    if isinstance(payload, dict):
        for key in ("channels", "results", "items"):
            val = payload.get(key)
            if isinstance(val, list) and val and isinstance(val[0], dict):
                return val
    if isinstance(payload, list) and payload and isinstance(payload[0], dict):
        return payload
    return []


def extract_channel_id_name(ch):
    cid = _pick(ch, ["id", "channelId", "serviceId", "service_id", "sid", "uid", "service"])
    name = _pick(ch, ["name", "channelName", "title", "serviceName"]) or "Unknown"
    if cid is None:
        cid = slugify(str(name))
    return str(cid), str(name)


def extract_channel_logo(ch):
    return _pick(ch, [
        "logo", "logo_url", "logoUrl",
        "channelLogo", "channel_logo",
        "service_logo", "serviceLogo",
        "image", "image_url"
    ])


def extract_events(ch: Channel) -> List[Event]:
    for key in ("events", "event", "schedule", "schedules", "programmes", "programs"):
        v = ch.get(key)
        if isinstance(v, list):
            return [normalise_event(e) for e in v if isinstance(e, dict)]
    for key in ch.keys():
        v = ch[key]
        if isinstance(v, dict):
            for k2 in ("events", "event", "schedule"):
                v2 = v.get(k2)
                if isinstance(v2, list):
                    return [normalise_event(e) for e in v2 if isinstance(e, dict)]
    return []

class GuideFetchError(Exception):
    pass


def _parse_epg_datetime(value: Optional[str]) -> Optional[int]:
    if not value:
        return None
    value = value.strip()
    if not value:
        return None
    if " " in value:
        stamp, tz = value.split(None, 1)
    else:
        stamp = value[:-5] if len(value) > 5 else value
        tz = value[-5:] if len(value) > 5 else ""
    if not tz.startswith(("+", "-")):
        tz = "+0000"
    ts = f"{stamp}{tz}"
    try:
        dt = datetime.strptime(ts, "%Y%m%d%H%M%S%z")
    except ValueError:
        return None
    return int(dt.timestamp())


def _text_or_none(elements: List[ET.Element]) -> str:
    for elem in elements:
        if elem is None:
            continue
        txt = (elem.text or "").strip()
        if txt:
            return txt
    return ""


def parse_epg_xml(xml_text: str) -> Dict[str, Any]:
    try:
        root = ET.fromstring(xml_text)
    except ET.ParseError as e:
        raise GuideFetchError(f"Invalid XML from feed: {e}") from e

    if root.tag != "tv":
        raise GuideFetchError(f"Unexpected root element '{root.tag}', expected 'tv'")

    channels: Dict[str, Dict[str, Any]] = {}

    for ch_elem in root.findall("channel"):
        cid = ch_elem.get("id") or ""
        name = _text_or_none(ch_elem.findall("display-name"))
        icon_elem = ch_elem.find("icon")
        logo = icon_elem.get("src") if isinstance(icon_elem, ET.Element) else None

        if not cid:
            cid = slugify(name or "channel")
        if not name:
            name = cid

        channels[cid] = {
            "id": str(cid),
            "name": name,
            "logo": logo,
            "events": [],
        }

    for prog in root.findall("programme"):
        ch_attr = prog.get("channel") or ""
        ch_id = ch_attr or slugify("channel")
        if ch_id not in channels:
            channels[ch_id] = {
                "id": str(ch_id),
                "name": str(ch_attr or "Unknown"),
                "logo": None,
                "events": [],
            }

        start_ts = _parse_epg_datetime(prog.get("start"))
        stop_ts = _parse_epg_datetime(prog.get("stop"))
        duration = None
        if isinstance(start_ts, int) and isinstance(stop_ts, int) and stop_ts >= start_ts:
            duration = int((stop_ts - start_ts) // 60)

        title = _text_or_none(prog.findall("title"))
        desc = _text_or_none(prog.findall("desc"))
        icon_elem = prog.find("icon")
        image = icon_elem.get("src") if isinstance(icon_elem, ET.Element) else None

        xmltv_ns = None
        onscreen = None
        for ep in prog.findall("episode-num"):
            system = (ep.get("system") or "").lower()
            text_val = (ep.text or "").strip()
            if not text_val:
                continue
            if system == "xmltv_ns":
                xmltv_ns = text_val
            elif system == "onscreen":
                onscreen = text_val

        categories = [
            (cat.text or "").strip()
            for cat in prog.findall("category")
            if (cat.text or "").strip()
        ]

        event_obj: Dict[str, Any] = {
            "startTime": start_ts,
            "endTime": stop_ts,
            "duration": duration,
            "name": title,
            "description": desc,
            "synopsis": desc,
            "image": image,
            "episode_xmltv_ns": xmltv_ns,
            "episode_onscreen": onscreen,
        }
        if categories:
            event_obj["categories"] = categories
        if xmltv_ns is None:
            event_obj.pop("episode_xmltv_ns", None)
        if onscreen is None:
            event_obj.pop("episode_onscreen", None)

        raw_snapshot = {
            "channel": ch_id,
            "start": prog.get("start"),
            "stop": prog.get("stop"),
            "title": title,
            "desc": desc,
            "icon": image,
            "episode_xmltv_ns": xmltv_ns,
            "episode_onscreen": onscreen,
            "categories": categories,
        }
        event_obj["_source"] = raw_snapshot

        channels[ch_id]["events"].append(event_obj)

    for ch in channels.values():
        ch["events"].sort(key=lambda e: (e.get("startTime") or 0, e.get("name") or ""))

        if not ch.get("logo"):
            ch.pop("logo", None)

    return {"channels": list(channels.values())}


def write_error_marker(out_dir: Path, start: int, message: str) -> None:
    ensure_dir(out_dir)
    raw_dir = out_dir / "raw"
    ensure_dir(raw_dir)
    (raw_dir / f"guide_{start}_ERROR.txt").write_text(message, encoding="utf-8")

def fetch_epg(url: str, session: Optional[requests.Session] = None, retries: int = 4, backoff: float = 1.7) -> Tuple[Dict[str, Any], str]:
    s = session or requests.Session()
    s.headers.update({
        "User-Agent": "elyobelyob-freely-split/1.0 (+https://github.com/elyobelyob/freely_tv_guide)",
        "Accept": "application/xml, text/xml;q=0.9, */*;q=0.8",
        "Accept-Language": "en-GB,en;q=0.9",
    })

    last_err = None

    for attempt in range(1, retries + 1):
        try:
            resp = s.get(url, timeout=(5, 30))
            if resp.status_code in (429, 502, 503, 504):
                raise GuideFetchError(f"HTTP {resp.status_code} from feed")
            if resp.status_code >= 400:
                raise GuideFetchError(f"HTTP {resp.status_code} from feed: {resp.text[:120]!r}")
            xml_text = resp.text
            try:
                payload = parse_epg_xml(xml_text)
                return payload, xml_text
            except GuideFetchError:
                raise
            except Exception as parse_exc:
                snippet = xml_text[:240].replace("\n", " ")
                raise GuideFetchError(
                    f"Failed to parse XML feed (status={resp.status_code}, len={len(xml_text)}): {snippet or '<empty response>'}"
                ) from parse_exc

        except (requests.RequestException, GuideFetchError) as e:
            last_err = e
            if attempt >= retries:
                break
            time.sleep(backoff ** attempt)

    raise GuideFetchError(f"Failed after {retries} attempts: {last_err}")



def write_outputs(payload: Any, out_dir: Path, start: int, raw_xml: Optional[str] = None) -> Dict[str, Any]:
    ensure_dir(out_dir)
    raw_dir = out_dir / "raw"
    chan_dir = out_dir / "channels"
    ensure_dir(raw_dir)
    ensure_dir(chan_dir)

    # Save raw API payload
    raw_path = raw_dir / f"guide_{start}.json"
    with open(raw_path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)

    if isinstance(raw_xml, str):
        (raw_dir / f"guide_{start}.xml").write_text(raw_xml, encoding="utf-8")

    channels = extract_channels(payload)
    index = {"start": start, "channels": []}

    for ch in channels:
        cid, name = extract_channel_id_name(ch)
        events = extract_events(ch)

        # Force local-only event images BEFORE writing files
        for e in events:
            img = (e.get("image") or "").strip()
            if isinstance(img, str) and img.startswith(("http://", "https://")):
                e["image"] = PROG_PLACEHOLDER
            if not e.get("image"):
                e["image"] = PROG_PLACEHOLDER

        # Channel + logo (use local placeholder if remote)
        logo_src = extract_channel_logo(ch)
        channel_obj = {"id": cid, "name": name}
        if logo_src:
            channel_obj["logo"] = CHAN_PLACEHOLDER if str(logo_src).startswith(("http://","https://")) else str(logo_src)

        out_obj = {
            "channel": channel_obj,                              # keep logo field
            "events": events,
            "compat": {"freesat_card": [{"event": events}]},     # legacy card compat
        }

        # Write per-channel JSON
        chan_path = chan_dir / f"{cid}.json"
        with open(chan_path, "w", encoding="utf-8") as f:
            json.dump(out_obj, f, ensure_ascii=False, indent=2)

        # Index entry (include logo if present)
        entry = {"id": cid, "name": name, "path": f"channels/{cid}.json"}
        if channel_obj.get("logo"):
            entry["logo"] = channel_obj["logo"]
        index["channels"].append(entry)

    # Write index
    with open(out_dir / "index.json", "w", encoding="utf-8") as f:
        json.dump(index, f, ensure_ascii=False, indent=2)

    return index


def main():
    ap = argparse.ArgumentParser(description="Fetch the Freeview XML feed and split into per-channel files")
    ap.add_argument("--url", default=os.getenv("EPG_URL", EPG_XML_URL),
                    help="EPG XML feed URL")
    default_start = os.getenv("EPG_START")
    if default_start is None:
        default_start = os.getenv("FREELY_START", "0")
    ap.add_argument("--start", type=int, default=int(default_start or 0),
                    help="UNIX timestamp (UTC) for the day start")
    ap.add_argument("--out", default=os.getenv("OUTPUT_DIR", "docs"),
                    help="Output folder (default: docs)")
    ap.add_argument("--dry-run", action="store_true",
                    help="Fetch but do not write outputs")

    args = ap.parse_args()

    if not args.start:
        ap.error("--start is required (UNIX timestamp, seconds)")

    try:
        payload, raw_xml = fetch_epg(args.url)
    except GuideFetchError as e:
        # Log, drop a marker, and exit 0 so later workflow steps can still run
        msg = (f"[freely_fetch_split] {e}\n"
               f"url={args.url}\n")
        print(msg, file=sys.stderr)
        write_error_marker(Path(args.out), args.start, msg)
        sys.exit(0)

    if args.dry_run:
        chs = extract_channels(payload)
        print(f"[freely_fetch_split] dry-run: channels={len(chs)} (no files written)")
        return

    index = write_outputs(payload, Path(args.out), args.start, raw_xml=raw_xml)
    print(f"[freely_fetch_split] wrote {len(index.get('channels', []))} channels to {args.out}/channels")

if __name__ == "__main__":
    main()
